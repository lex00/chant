---
type: task
status: pending
---
# Research and fix ollama prompt handling for complex specs

## Problem

Ollama tool calling works for simple specs but fails on complex ones:

| Spec Type | Prompt Tokens | Tool Calls | Result |
|-----------|---------------|------------|--------|
| Simple test (write file) | ~1200 | ✅ Yes | Success |
| Complex refactoring | ~2800 | ❌ No | Model outputs text plan only |
| Complex with 14b model | ~2800 | ✅ Yes | Calls tools but generates poor code |

## Findings

1. **Tool calling mechanism works** - verified with simple spec
2. **Prompt size matters** - qwen2.5:7b stops calling tools above ~1500 tokens
3. **Model quality issues** - even when calling tools, model:
   - Hallucinates code instead of reading existing code
   - Uses `cargo` directly instead of `just` commands
   - Doesn't follow spec instructions precisely

## Research Questions

1. Can the standard prompt be optimized to be shorter?
2. Should ollama have a different prompt than Claude?
3. Can split create smaller, more focused specs automatically?
4. What's the optimal prompt token limit for qwen2.5:7b vs 14b?
5. Should the prompt include explicit instructions like "read before write"?

## Proposed Solutions

### Option A: Optimize standard prompt
- Reduce boilerplate in standard.md prompt
- Create ollama-specific prompt variant
- Keep under 1000 tokens for system prompt

### Option B: Improve split for ollama
- Split should create even smaller member specs
- Each spec should be one atomic action
- Include "read X first" instructions

### Option C: Add ollama-specific behavior
- In agent.rs, add logic to:
  - Break complex tasks into steps
  - Force read_file before write_file
  - Use just commands instead of cargo

## Acceptance Criteria

- [ ] Document optimal prompt token limits for qwen2.5 models
- [ ] Create or identify a short prompt suitable for ollama
- [ ] Test spec execution with optimized prompt
- [ ] Document recommendations for ollama usage

## Notes

This is a research/task spec, not a code spec. The goal is to understand and document how to make ollama work reliably for spec execution.
