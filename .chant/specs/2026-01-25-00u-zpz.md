---
type: code
status: completed
target_files:
- src/provider.rs
- Cargo.toml
model: claude-haiku-4-5-20251001
---
# Windows build compatibility - curl dependency gap

## Problem

The Ollama/OpenAI provider implementation uses `curl` via `std::process::Command`. This works on:
- ✅ macOS (curl pre-installed)
- ✅ Linux (curl usually pre-installed)
- ❌ Windows (curl NOT pre-installed)

## Options

1. **Add ureq with native-tls** - Use system TLS instead of rustls (avoids ring C compilation)
2. **PowerShell fallback** - Use `Invoke-WebRequest` on Windows when curl unavailable
3. **Document requirement** - Just tell Windows users to install curl
4. **Bundle curl** - Include curl binary for Windows builds

## Recommended: Option 1

Use `ureq` with `native-tls` feature:
```toml
[dependencies]
ureq = { version = "2", default-features = false, features = ["native-tls"] }
```

This uses the system's TLS library (Schannel on Windows, OpenSSL on Linux, Security.framework on macOS) instead of rustls/ring which requires C compilation.

## Acceptance Criteria

- [x] Replace curl subprocess with ureq HTTP library
- [x] Use native-tls feature to avoid C compilation issues
- [x] Test build on Windows (CI or manual)
- [x] Test build on Linux (CI)
- [x] Test build on macOS (local)
- [x] All provider tests still pass
- [x] Streaming still works correctly