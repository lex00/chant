---
type: code
status: completed
commits:
- 3596b78
- 0a53ab6
completed_at: 2026-01-29T02:17:13Z
model: opus
---
# Diagnose and fix chant list performance issue

## Problem

`chant list` rendering is slow (~0.867 seconds) even for 11 specs. Used to be instant (hundreds of specs printed immediately).

**Key insight from user:**
- `chant list | grep` is fast (data loading is fine)
- Full output rendering is slow (terminal display bottleneck)

**Observed:**
- Takes ~0.9 seconds to display 11 specs
- Used to be instant
- Output has emoji (üë§ ‚óè ‚Ü©), colors, and formatting

**Suspect causes:**
1. Terminal rendering overhead (emoji, colors, unicode)
2. Expensive formatting per spec (time ago calculation, git author lookup)
3. Flushing output per spec instead of batching
4. Recent code changes that added per-spec display operations

## Investigation Needed

1. **Profile git operations in list:**
   - List shows author (üë§ username) and activity time (‚Ü© 1h)
   - Are these running `git log` or `git show` per spec?
   - Count actual git subprocess calls

2. **Find recent changes:**
   - When was author/activity display added?
   - What commit introduced the slowdown?
   - Git blame on list display code

3. **Batch git operations:**
   - Can author lookups be batched?
   - Can we get all spec commits in one git command?
   - Cache git results across specs?

4. **Consider lazy loading:**
   - Only lookup author/activity when needed
   - Add `--simple` flag for fast list without metadata
   - Or make author/activity opt-in with `--verbose`

## Acceptance Criteria

- [x] Identify root cause of slowdown
- [x] Implement fix
- [x] Verify `chant list` is fast (<0.1s for 11 specs)
- [x] Add tests if needed
- [x] All tests passing

## Solution

**Root Cause:** Each spec in the list triggered 2 separate git subprocess calls:
- `get_file_creator()` - runs `git log --diff-filter=A --format=%an --follow -- <file>`
- `get_file_last_modified()` - runs `git log -1 --format=%aI -- <file>`

For 11 specs, this meant 22 git subprocess invocations, each with ~40ms overhead = ~0.9 seconds.

**Fix:** Replaced per-spec git calls with a batch loading approach:
1. Added `batch_load_spec_git_metadata()` function that uses a single git command to get metadata for all spec files
2. Limited git history traversal to last 200 commits for speed (sufficient for active specs)
3. Creator info only fetched when `--created-by` filter is used (requires full history scan)

**Performance:**
- Before: ~0.9 seconds for 11 specs
- After: ~0.055 seconds for 11 specs (16x faster)

## Agent Output

2026-01-29T02:17:13Z

```
I'll start by reading the spec file and understanding the codebase structure for the `chant list` command.
Let me look at the list command implementation and the activity module which likely handles author/activity display.
The spec.rs file is too large. Let me search for the list command specifically and look at the render module.
Now let me look at the actual cmd_list function in cmd/spec.rs.
I found the issue. In the `cmd_list` function (lines 1431-1442), for each spec, there are calls to `get_file_creator` and `get_file_last_modified`. These are likely expensive git operations that run individually for each spec. Let me look at these functions.
I found the root cause. For each spec in the list, the code makes **two git subprocess calls**:
1. `get_file_creator()` - runs `git log --diff-filter=A --format=%an --follow -- <file>` 
2. `get_file_last_modified()` - runs `git log -1 --format=%aI -- <file>`

For 11 specs, that's 22 git subprocess calls, which explains the ~0.9 second delay. Let me verify when these were added by checking git blame.
These were added recently (Jan 28, 2026). Now I understand the issue clearly. The solution should batch these git operations instead of running them per spec. Let me check if there's a way to get all this info in a single git command.
I can get all the information in a single git command. Let me plan the solution:

**Root Cause Identified:**
- Each spec in the list triggers 2 git subprocess calls (`get_file_creator` and `get_file_last_modified`)
- For 11 specs = 22 git subprocess invocations
- Each subprocess has overhead (~40ms each) = ~0.9 seconds total

**Solution:**
1. Batch all git log operations into a single call before the loop
2. Parse the results into a HashMap for fast lookup during the loop
3. The single git command can get all commit data for all spec files at once

Let me implement this fix.
Now I need to see how the filters use the creator and last_modified. The filter code also calls these functions per spec. Let me read those filter sections.
The filter operations also use the per-spec git calls. My solution needs to:

1. Create a function to batch load all spec git metadata (creator and last_modified) in a single git call
2. Use this batch data for both filtering and display

Let me implement the solution.
Now I'll add a new function that batch-loads all spec git metadata using a single git command, and modify the `cmd_list` function to use it. Let me first look at the structure of the spec file to understand where to add the batch function.
Now I understand the structure. I need to:

1. Add a `SpecGitMetadata` struct to hold creator and last_modified
2. Add a `batch_load_spec_git_metadata` function that gets all this data in a single git call
3. Modify `cmd_list` to call this once and use the cached data

Let me add the batch loading function and struct after the existing per-file functions.
Now I need to modify the `cmd_list` function to use the batch-loaded metadata. Let me read the current implementation again to make the changes.
Now I have a clear picture of where changes are needed. I need to:

1. Load the batch metadata once after specs are loaded (before filters)
2. Use the batch metadata in the filter operations
3. Use the batch metadata in the display loop

Let me make these changes:
Now update the creator filter to use the batch metadata:
Now update the activity since filter:
Now update the display loop to use batch metadata:
Now let's run cargo fmt and clippy to ensure the code is clean:
Good - the old functions are now unused. I should remove them or mark them as potentially useful for single-file operations. Since the batch function is more efficient for the list command, but the old functions might still be useful for single-file operations elsewhere in the codebase, let me check if they're used anywhere else.
They're not used anywhere else. Since we replaced them with the batch function, I'll add `#[allow(dead_code)]` to keep them around in case they're useful for single-file operations later, or I could remove them. Let me check if there's any other place in the codebase that might want single-file operations.
The functions are not used elsewhere. Since they might be useful for future single-file lookups (e.g., cmd_show could benefit from them), I'll add `#[allow(dead_code)]` to suppress the warnings:
No warnings. Now let's build the binary and test the performance:
Hmm, the time is still 1.2 seconds. Let me investigate - maybe the batch git command isn't working as expected. Let me add some debug output.
The git command works but it's scanning the entire history. Let me check if there's a way to make it faster. The issue might be that git is traversing many commits. Let me time how fast the git command itself is:
The git command is fast (~0.1s). So the issue might be elsewhere. Let me profile where the time is going:
Interesting! When using `--count` (which doesn't show the metadata), it's 0.17s. So there might be a baseline cost. 

... (output truncated, 10619 chars total)```
