---
type: research
status: completed
origin:
  - 2026-01-26-00m-13d
target_files:
  - .chant/specs/2026-01-26-00q-thn.md
---

# Research additional semantic linting rules

## Context

New linting rules were added to improve spec quality:
- **Complexity warnings**: specs with >5 criteria, >5 files, >500 words
- **Coupling warnings**: specs referencing other spec IDs
- **Model waste warnings**: opus/sonnet on simple specs
- **Config validation**: agent commands, prompts, parallel limits

## Research Questions

1. What other semantic issues in specs could be detected?
2. What config validation rules are missing?
3. What patterns indicate poor spec quality?
4. What rules would help enforce haiku-friendly specs?

## Analysis Findings

### Current Implementation

**Existing Linting Rules (src/cmd/spec.rs)**
- **Complexity warnings**: 3 checks
  - >5 acceptance criteria
  - >5 target files
  - >500 words in description
- **Coupling warnings**: Detects spec ID references in body (with driver/member exceptions)
- **Model waste warnings**: Expensive models (opus/sonnet) on simple specs
- **Type-specific validation**: Documentation and research specs require specific fields

**Current Threshold Constants**
- `COMPLEXITY_THRESHOLD_CRITERIA`: 5
- `COMPLEXITY_THRESHOLD_FILES`: 5
- `COMPLEXITY_THRESHOLD_WORDS`: 500
- `SIMPLE_THRESHOLD_CRITERIA`: 3
- `SIMPLE_THRESHOLD_FILES`: 2
- `SIMPLE_THRESHOLD_WORDS`: 200

### Analyzed Spec Dataset

**16 total specs** with varying states:
- 7 completed (status: completed)
- 8 pending (status: pending)
- 2 cancelled (status: cancelled)
- 1 research (status: pending)

**Current Lint Results**: All 16 specs pass with 7 warnings for high complexity

---

## 5+ New Linting Rules Identified

### 1. **Missing Acceptance Criteria (ERROR)**

**Severity**: Error (blocks readiness)

**Description**: Specs without "## Acceptance Criteria" section or with empty acceptance criteria are unmeasurable and difficult to complete.

**Detection**:
- Look for "## Acceptance Criteria" heading in body
- Check if section exists and has at least one checkbox item
- Report spec ID if missing or empty

**Implementation Complexity**: Low
- Leverage existing `count_total_checkboxes()` method in Spec struct
- Return 0 if no Acceptance Criteria section found
- Flag as error if count == 0

**Example Issue**: Spec 2026-01-26-00h-8fa.md has title but minimal body, likely missing criteria

**Current Gap**: Lint only warns on complexity, doesn't require criteria existence

---

### 2. **Vague Acceptance Criteria (WARNING)**

**Severity**: Warning (hints at poor quality)

**Description**: Acceptance criteria without measurable/verifiable outcomes indicate unclear requirements.

**Patterns to Detect**:
- Single-word criteria (e.g., "- [ ] Implementation")
- Criteria containing only pronouns (e.g., "- [ ] It works")
- Criteria with "and" combining multiple concerns (e.g., "- [ ] Add feature AND fix bug AND update docs")
- Criteria without action verbs (except for cross-files: "All tests pass", "Code builds")

**Detection Examples**:
```markdown
- [ ] Implement feature          ❌ Too vague
- [ ] Add login button           ✓ Clear and measurable
- [ ] Bug and feature and docs   ❌ Compound
- [ ] Update tests and docs      ❌ Often too broad
```

**Implementation Complexity**: Medium
- Need NLP-style heuristics or pattern matching
- Word count check (<4 words likely too vague)
- Conjunction detection (AND/OR)
- Verb extraction

**Recommendation**: Low priority - useful feedback but subjective

---

### 3. **Missing or Mismatched target_files (WARNING)**

**Severity**: Warning for code specs (error for type=code)

**Description**: Code specs should declare target_files; missing or vague targets make testing and impact analysis difficult.

**Rules**:
- `type: code` → `target_files` required (warn if missing)
- `type: documentation` → `target_files` required
- `type: research` → `target_files` required (output file path)
- `type: task` → optional but recommended
- `type: driver/group` → optional (members declare files)

**Edge Cases**:
- Research specs with `origin` but no `target_files` (where does output go?)
- Code specs with empty target_files list
- Specs with target_files not matching git structure

**Implementation Complexity**: Low-Medium
- Check spec type and validate required fields
- Optionally check paths exist in repo (medium complexity)

**Current Gaps**: Only research/documentation warn on missing target_files

---

### 4. **Invalid Status Transitions (ERROR)**

**Severity**: Error (data integrity)

**Description**: Some status transitions are invalid and indicate manual errors or corruption.

**Valid Transitions** (based on spec.rs SpecStatus):
```
pending   → ready, blocked, completed, cancelled
ready     → in_progress, blocked, cancelled
in_progress → completed, blocked, failed, cancelled
blocked   → pending, ready, cancelled
completed → [terminal]
failed    → [needs attention]
cancelled → [terminal]
```

**Invalid Transitions**:
- `completed` → `pending` (can't undo completion)
- `cancelled` → `in_progress` (can't resurrect)
- `failed` → `ready` (must be manually reviewed)
- `blocked` → `completed` (must clear blocker first)

**Implementation Complexity**: Low
- Build state machine as HashMap
- Check if (current, next) transition is valid
- Warn on invalid transitions found in git history

**Note**: Requires parsing git history or commit metadata

---

### 5. **Circular or Excessive Dependencies (WARNING)**

**Severity**: Warning (indicates poor design)

**Description**: Specs with circular dependencies or deep dependency chains block execution and indicate specs should be reorganized.

**Patterns to Detect**:
- Circular dependencies: `A depends_on B, B depends_on A`
- Deep chains: `A → B → C → D → E` (>3 levels)
- Many dependents: Specs with 4+ other specs depending on them
- Orphaned deps: `depends_on` references non-existent specs (already checked)

**Example Issues**:
```yaml
spec A:
  depends_on: [B, C, D, E]    # Too many dependencies

spec B:
  depends_on: [A]             # Circular!
```

**Implementation Complexity**: Medium
- Build dependency graph
- Cycle detection (DFS/topological sort)
- Path length analysis
- Transitive dependency checking

**Data Available**:
- `depends_on` field in frontmatter
- All spec IDs loaded in cmd_lint

---

### 6. **Model Mismatch for Spec Type (WARNING)**

**Severity**: Warning (cost optimization)

**Description**: Certain spec types shouldn't use expensive models:
- `type: task` with opus/sonnet (tasks are manual work, don't need expensive models)
- `type: documentation` with opus (documentation is structured, haiku is sufficient)
- Research specs with haiku (might not have enough reasoning for complex analysis)

**Rules**:
- `task` → haiku preferred (manual work doesn't benefit from smart models)
- `documentation` → haiku sufficient (follows templates)
- `research` → sonnet/opus recommended (benefits from reasoning)
- `code` → haiku by default, sonnet for complex logic
- `driver/group` → opus recommended (coordinates member specs)

**Implementation Complexity**: Low
- Add type-to-model-preference mapping
- Warn when model conflicts with type

**Note**: Different from existing "model waste" check (which flags expensive models on simple specs)

---

### 7. **Duplicate or Conflicting target_files (WARNING)**

**Severity**: Warning (indicates coordination issue)

**Description**: Multiple pending/in_progress specs targeting the same file could lead to merge conflicts or lost work.

**Detection**:
- Find all pending/in_progress specs
- Extract target_files from each
- Warn if same file appears in multiple specs
- Suggest grouping as driver or clarifying dependencies

**Implementation Complexity**: Medium
- Requires loading all specs
- Building file-to-specs map
- Filtering by status

**Current Data**: cmd_lint already loads all specs, has status available

**Example**:
```
⚠ Conflict: src/main.rs targeted by:
  - 2026-01-26-013-7u4 (pending)
  - 2026-01-26-014-f5b (pending)
```

---

### 8. **Missing Model for Completed Code Specs (ERROR)**

**Severity**: Warning (audit trail)

**Description**: According to CLAUDE.md, completed code specs should have model field added to frontmatter showing which model executed the work.

**Rule**: `status: completed` AND `type: code` → must have `model` field

**Detection**: Simple check in lint

**Implementation Complexity**: Low

**Data**: 7 completed specs - check if all have model field

---

### 9. **Prompt Reference Validation (ERROR)**

**Severity**: Error (execution blocker)

**Description**: Specs referencing invalid or non-existent prompts will fail at execution time.

**Patterns**:
- `prompt:` field in frontmatter
- Compare against prompts in `.chant/prompts/` directory
- Warn if prompt doesn't exist

**Implementation Complexity**: Low
- Check if prompt file exists
- List available prompts in error message

**Available Prompts** (from directory listing):
- doc-audit.md
- documentation.md
- merge-conflict.md
- ollama.md
- parallel-cleanup.md
- research-analysis.md
- research-synthesis.md
- split.md
- standard.md

---

### 10. **Agent Command Validation (ERROR)**

**Severity**: Error (execution blocker)

**Description**: Config references agent commands that may not exist or be executable.

**Rules**:
- Each agent in `parallel.agents[].command` should be a valid shell command
- Should appear in PATH or be resolvable
- Warn if command not found

**Implementation Complexity**: Medium-High
- Requires shell command resolution
- Might need to handle platform differences
- Consider false positives (commands that exist only sometimes)

**Current Config**:
```yaml
agents:
  - command: claude1
  - command: claude2
  - command: claude3
```

All point to "claude" family commands, likely aliases or wrapper scripts.

---

## Categorization Summary

| Rule | Severity | Complexity | Type | Priority |
|------|----------|-----------|------|----------|
| Missing Acceptance Criteria | ERROR | Low | Spec Content | **High** |
| Missing target_files (code specs) | ERROR | Low-Med | Spec Metadata | **High** |
| Invalid Status Transitions | ERROR | Low | Spec Metadata | **High** |
| Vague Acceptance Criteria | WARNING | Medium | Spec Content | Medium |
| Circular/Deep Dependencies | WARNING | Medium | Spec Graph | Medium |
| Model Mismatch for Type | WARNING | Low | Spec Metadata | Medium |
| Duplicate target_files | WARNING | Medium | Spec Graph | Medium |
| Missing Model on Completed Specs | WARNING | Low | Spec Audit | Low |
| Invalid Prompt Reference | ERROR | Low | Config Validation | **High** |
| Invalid Agent Commands | ERROR | Medium | Config Validation | High |

---

## Implementation Priority Recommendation

### Phase 1: High-Priority Errors (Low Complexity)
1. **Missing Acceptance Criteria** (prevents incomplete specs from proceeding)
2. **Missing target_files for code specs** (enforces discipline)
3. **Invalid Status Transitions** (catches data corruption)
4. **Invalid Prompt Reference** (prevents execution failures)

### Phase 2: Medium-Priority Warnings
5. **Circular/Deep Dependencies** (design smell)
6. **Model Mismatch for Type** (cost optimization)
7. **Duplicate target_files** (conflict prevention)

### Phase 3: Low-Priority Warnings
8. **Vague Acceptance Criteria** (subjective, needs NLP)
9. **Missing Model on Completed Specs** (audit trail)
10. **Invalid Agent Commands** (complex resolution logic)

---

## Integration Points

**All new rules fit into existing `cmd_lint()` function**:
```rust
fn cmd_lint() {
    // Existing passes:
    // 1. Parse error check
    // 2. Title check
    // 3. depends_on reference check
    // 4. Type-specific validation ✓
    // 5. Complexity validation ✓
    // 6. Coupling validation ✓
    // 7. Model waste validation ✓

    // New passes:
    // 8. Acceptance criteria check (NEW)
    // 9. Status transitions check (NEW)
    // 10. target_files validation (NEW)
    // 11. Prompt reference check (NEW)
    // 12. Agent command validation (NEW)
    // 13. Dependency graph analysis (NEW)
    // 14. Duplicate target_files check (NEW)
    // 15. Model mismatch check (NEW)
}
```

---

## Acceptance Criteria

- [x] Document 5+ potential new linting rules
- [x] Categorize by severity (error vs warning)
- [x] Identify implementation complexity for each
- [x] Recommend priority order for implementation
